{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOR7Ca/9k9vP/LbNnp6EnuZ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/saipraneeth009/git_repo/blob/main/Startoon_Labs_Assignment.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "# **Assignment**\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "EZ3BPoU5alKS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Coding Section** : -\n",
        "\n",
        "Could we sum it?\n",
        "\n",
        "Let Ankur has given a large weight W, and a list of smaller weights in an array. He needs to write a \n",
        "code in order to find \"can we form weight W or not, using smaller weights\". He only knows dp \n",
        "solution. Could you write a code solution for him without using dp.\n",
        "\n",
        "*Constraint*: - list size <= 12\n",
        "\n",
        "*Sample Input1*: -\n",
        "W = 15\n",
        "list = {4, 3, 5, 6, 4}\n",
        "Output: - True \n",
        "Explanation: -\n",
        "15 =4 + 5 + 6.\n",
        "\n",
        "*Sample Input2*: -\n",
        "W = 9\n",
        "list = {4, 1, 3, 7}\n",
        "Output: - False.\n",
        "Explanation: - There is no way to sum up 7.\n",
        "\n",
        "**Descriptive Section** : -\n",
        "\n",
        "1. How Do You Handle Missing or Corrupted Data in a Dataset?\n",
        "2. What Are the Three Stages of Building a Model in Machine Learning"
      ],
      "metadata": {
        "id": "QEvIBn4uaIP8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Coding section**"
      ],
      "metadata": {
        "id": "YOT9fC84adjy"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "gBTEcLwfaA0o"
      },
      "outputs": [],
      "source": [
        "def can_we_form_weight(W, weights):\n",
        "    if W == 0:\n",
        "        return True\n",
        "    if len(weights) == 0 or W < 0:\n",
        "        return False\n",
        "\n",
        "    # Check if we can form the weight W without using the last weight\n",
        "    if can_we_form_weight(W, weights[:-1]):\n",
        "        return True\n",
        "\n",
        "    # Check if we can form the weight W using the last weight\n",
        "    if can_we_form_weight(W - weights[-1], weights[:-1]):\n",
        "        return True\n",
        "\n",
        "    return False"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Test the function with the sample input 1\n",
        "W = 15\n",
        "weights = [4, 3, 5, 6, 4]\n",
        "print(can_we_form_weight(W, weights))  "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "vrQ_07pfcZC0",
        "outputId": "5cb1cf21-ff08-475d-c64e-6bc2d465ca68"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "True\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Test the function with the sample input 2\n",
        "W = 9\n",
        "weights = [4, 1, 3, 7]\n",
        "print(can_we_form_weight(W, weights))  "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "a9I3i63Xcb9t",
        "outputId": "ecd5e9d6-6614-4923-8343-669025f2b713"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "False\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# test the function with self input\n",
        "W = 12\n",
        "weights = [3, 1, 4, 5]\n",
        "print(can_we_form_weight(W, weights))  "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "8EqLl5zJczjb",
        "outputId": "fed5cc2b-c86f-4aad-bb55-e677fa5906e4"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "True\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Descriptive Section**"
      ],
      "metadata": {
        "id": "31vTiszyeXbx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        ">**How Do You Handle Missing or Corrupted Data in a Dataset?**\n",
        "\n",
        "Dealing with missing or corrupted data in a dataset involves several steps. First, it's important to identify and understand the missing or corrupted data present. This can include null values, NaN, blank cells, or other anomalies.\n",
        "\n",
        "Once identified, you should analyze the causes behind the missing or corrupted data. This helps in understanding the factors that led to the data being missing or corrupted, such as data collection errors or system failures.\n",
        "\n",
        "There are various approaches to handle missing or corrupted data:\n",
        "\n",
        "1. **Removal**: If the amount of missing data is small and doesn't significantly impact the analysis, you may choose to remove the affected records or features. However, this should be done carefully, considering the impact on the representativeness and statistical properties of the dataset.\n",
        "\n",
        "2. **Imputation**: Imputation involves filling in missing values with estimated or substituted values. Common imputation techniques include using the mean, median, or mode of non-missing values, forward or backward filling, linear interpolation, machine learning-based imputation, or multiple imputation.\n",
        "\n",
        "3. **Flagging**: Instead of imputing missing data, you can create a separate indicator column to flag the presence of missing values. This preserves the missingness information, which can be used as a feature in the analysis.\n",
        "\n",
        "4. **Domain-specific methods**: Depending on the dataset and domain knowledge, specialized methods like seasonal decomposition or autoregressive models can be used for imputation, particularly for time series data.\n",
        "\n",
        "When handling missing or corrupted data, it's important to consider the limitations and potential biases introduced by the chosen approach. Documenting the assumptions and methods used ensures transparency and reproducibility of the analysis.\n",
        "\n",
        "Validation and sensitivity analysis are crucial to assess the impact of the chosen approach. Evaluating different handling techniques and considering multiple imputation or bootstrapping can account for uncertainty.\n",
        "\n",
        "Ultimately, the choice of handling missing or corrupted data depends on the specific dataset, analysis goals, and domain knowledge. Careful evaluation of the trade-offs and implications of each approach is necessary.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "yok9puHDehYu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "> **What Are the Three Stages of Building a Model in Machine Learning?**\n",
        "\n",
        "The three stages of building a model in machine learning are:\n",
        "\n",
        "1. **Data Preprocessing**: The first stage involves preparing and preprocessing the dataset to ensure it is suitable for training a machine learning model. This stage typically includes the following steps:\n",
        "   - **Data Cleaning**\n",
        "   - **Feature Selection/Extraction**\n",
        "   - **Data Transformation**\n",
        "   - **Train-Test Split**\n",
        "\n",
        "2. **Model Building**: In this stage, the actual machine learning model is selected, trained, and evaluated using the preprocessed dataset. Key steps include:\n",
        "   - **Model Selection**\n",
        "   - **Training**\n",
        "   - **Hyperparameter Tuning**\n",
        "   - **Model Evaluation**\n",
        "\n",
        "3. **Model Deployment and Monitoring**: After the model is built and evaluated, it can be deployed for real-world applications. This stage involves:\n",
        "   - **Deployment**\n",
        "   - **Monitoring**\n",
        "   - **Maintenance and Iteration**\n",
        "\n",
        "These three stages encompass the typical workflow in building a machine learning model, starting from data preprocessing and preparation, moving on to model selection, training, and evaluation, and finally deploying and maintaining the model in a real-world scenario."
      ],
      "metadata": {
        "id": "SEBgc9V4euHN"
      }
    }
  ]
}